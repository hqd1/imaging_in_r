---
title: "MS Lesion Segmentation"
output:
  ioslides_presentation:
    widescreen: yes
    css: ../styles.css
    keep_md: true
  beamer_presentation: 
    keep_md: true
bibliography: ../refs.bib       
---

```{r setup, include=FALSE}
library(methods)
library(ggplot2)
# library(pander)
library(knitr)
knitr::opts_chunk$set(echo = TRUE, comment = "", cache=TRUE, warning = FALSE)
```

## Overall Pipeline

<img src="flow.png" style="width: 75%; display: block; margin: auto;"> 



## Background

- Obtaining manual lesion segmentations is often resource intensive.
- "Gold standard": Inter- and Intra-rater variability
- Accurate and efficient methods for automatic segmentation are necessary for scalability and research progress.
- In this tutorial, we will learn how to train and apply OASIS [@sweeney2013oasis], an automatic lesion segmentation model, to obtain predicted lesion probability maps.
    - relies on intensity-normalized data



```{r loading, echo=FALSE, message=FALSE, cache = FALSE}
library(ms.lesion)
library(neurobase)
library(fslr)
library(scales)
library(oasis)
library(dplyr)
tr_files = get_image_filenames_list_by_subject(
  group = "training", type = "coregistered")
ts_files = get_image_filenames_list_by_subject(
  group = "test", type = "coregistered")
# tr_t1s = lapply(tr_files, function(x) readnii(x["T1"]))
# tr_t2s = lapply(tr_files, function(x) readnii(x["T2"]))
tr_flairs = lapply(tr_files, function(x) readnii(x["FLAIR"]))
# tr_masks = lapply(tr_files, function(x) readnii(x["Brain_Mask"]))
tr_golds = lapply(tr_files, function(x) readnii(x["mask"]))
tr_golds = lapply(tr_golds, function(x) {
  check_mask_fail(x)
  x > 0
})
# ts_t1s = lapply(ts_files, function(x) readnii(x["T1"]))
# ts_t2s = lapply(ts_files, function(x) readnii(x["T2"]))
tr_pds = ts_pds = NULL
ts_flairs = lapply(ts_files, function(x) readnii(x["FLAIR"]))
# ts_masks = lapply(ts_files, function(x) readnii(x["Brain_Mask"]))
ts_golds = lapply(ts_files, function(x) readnii(x["mask"]))
ts_golds = lapply(ts_golds, function(x) {
  check_mask_fail(x)
  x > 0
})
# John added for code to work
```

## Visualization
- Here's the FLAIR volume for training subject 01.

```{r over_show_run, echo=FALSE}
les_mask = tr_golds$training01
# john code for choosing z-slice with highest # of voxels
w = which(les_mask > 0, arr.ind = TRUE)
w = as.data.frame(w, stringsAsFactors = FALSE)
keep_dim = w %>% group_by(dim3) %>% 
  tally() %>% 
  arrange(desc(n)) %>% 
  ungroup %>% slice(1) 
keep_dim = keep_dim$dim3
w = w[ w$dim3 %in% keep_dim, ]
#xyz = floor(colMeans(w))
xyz = c(119,254,343)
ortho2(robust_window(tr_flairs$training01), xyz = xyz)
```

## Visualization
- And here's the manual lesion segmentation overlayed.

```{r over_show_run2, echo=FALSE}
# john code for choosing z-slice with highest # of voxels
w = which(les_mask > 0, arr.ind = TRUE)
w = as.data.frame(w, stringsAsFactors = FALSE)
keep_dim = w %>% group_by(dim3) %>% 
  tally() %>% 
  arrange(desc(n)) %>% 
  ungroup %>% slice(1) 
keep_dim = keep_dim$dim3
w = w[ w$dim3 %in% keep_dim, ]
#xyz = floor(colMeans(w))
xyz = c(119,254,343)
ortho2(robust_window(tr_flairs$training01), les_mask, xyz = xyz, col.y = scales::alpha("red", 0.5))
```

## MS Lesion Segmentation with OASIS
- **O**ASIS is **A**utomated **S**tatistical **I**nference for **S**egmentation [@sweeney2013oasis].
- OASIS takes FLAIR, T1, T2, and PD (optional) images. 
    - Produces OASIS probability maps of MS lesion presence.
    - These can be thresholded into a binary lesion segmentation.
- The OASIS model is based on a logistic regression. 
  - Regress binary manual segmentation labels on the images, smoothed versions of the images, and some interaction terms (e.g., supervised learning).
  - Performed well compared to common machine learning models [@sweeney2014comparison]

## Default OASIS Model
- The OASIS library comes with default parameters that can be used to generate probability maps for new test subjects.
  - The default model was trained on approximately 100 MS subjects and 30 healthy subjects with manual segmentations.
- Here we apply `oasis_predict` with the default model to obtain OASIS probability maps for the test subjects.

```{r default_predict_ts_show, eval=FALSE}
library(oasis)
default_predict_ts = function(x){
  res = oasis_predict(
      flair=ts_flairs[[x]], t1=ts_t1s[[x]], 
      t2=ts_t2s[[x]], pd=ts_pds[[x]], 
      brain_mask = ts_masks[[x]], 
      preproc=FALSE, normalize=TRUE, 
      model=oasis::oasis_model)
  return(res)
}
default_probs_ts = lapply(1:3, default_predict_ts)
```

```{r default_predict_run, eval=TRUE, echo=FALSE}
default_ts = lapply(ts_files, 
	function(x) readnii(x["Default_OASIS"]))
```

## Vizualization of probability map
- Here's the probability map for test subject 01.

```{r viz_01, echo=FALSE}
les_mask = default_ts[[1]]
les_mask[les_mask < .05] = 0
ortho2(ts_flairs$test01, les_mask, xyz = xyz)
```

## Thresholding: Getting a binary map 

- We must choose a cutoff to binarize the OASIS probability maps.
- The `binary` argument in the `oasis_predict` function is FALSE by default, resulting in the output being the probability map.
    - Setting `binary=TRUE` will return the thresholded version, using the input to the `threshold` argument (default = 0.16).
    - 0.16 was obtained via a validation set allowing for a 0.5% false positive rate.
- In practice, we might want to use a grid search over thresholds and cross validation to choose the cutoff.

## Vizualization of binary map
- Here's the binary mask for test subject 01, using the default 0.16 threshold:

```{r viz_02, echo=FALSE}
les_mask = default_ts[[1]] > 0.16
ortho2(ts_flairs$test01, les_mask, col.y=alpha("red", 0.5), xyz = xyz)
```

## Default OASIS Model
- To evaluate how the default model with default threshold performs, we'll compare the predictions to our manual segmentations.

```{r default_predict_tr_show, eval=FALSE}
default_predict_ts = function(x){
  res = oasis_predict(
      flair=ts_flairs[[x]], t1=ts_t1s[[x]], 
      t2=ts_t2s[[x]], pd=ts_pds[[x]], 
      brain_mask=ts_masks[[x]], 
      preproc=FALSE, normalize=TRUE, 
      model=oasis::oasis_model, binary=TRUE)
  return(res)
}
default_probs_ts = lapply(1:3, default_predict_ts)
```

```{r default_predict_tr_run, eval=TRUE, echo=FALSE}
default_ts = lapply(ts_files, 
	function(x){
		img = readnii(x["Default_OASIS"])
		img = img > 0.16
		return(img)
	})
```

## Default OASIS Model Results
- Here's the FLAIR volume for test subject 01 with the OASIS segmentation overlayed.

```{r over_05_run, echo=FALSE}
les_mask = default_ts[[1]]
ortho2(ts_flairs$training01, les_mask, col.y = alpha("red", 0.5))
```

## Default OASIS Model Results

Sorensenâ€“Dice coefficient

  - Similarity measure between two samples 
  - Ranges from 0 to 1
  - (TP) - true positive, (FP) - false positive, (FN) - false negative

$$D = \frac{2TP}{2TP + FP + FN}$$



## Default OASIS Model Results
Dice coeffients for the test subjects  

```{r table1, echo=FALSE}
dice = function(x){
  return((2*x[2,2])/(2*x[2,2] + x[1,2] + x[2,1]))
}
tbls_df = lapply(1:3, function(x) table(
  c(ts_golds[[x]]), c(default_ts[[x]]))
  )
dfDice = sapply(tbls_df, dice)

diceDF = data.frame(Subject=factor(rep(1:3)), 
                    Dice=c(dfDice))
g = ggplot(diceDF, aes(x=Subject, y=Dice)) + 
       geom_histogram(position="dodge", stat="identity")
print(g)
```

## Improving Results
- The default model is picking up some false positives in the lower part of the brain. 
- We might improve the results by adjusting the threshold.
- Let's optimize the threshold on the training data using a grid search (in practice, we might do cross-validation)

```{r table1_run, echo=FALSE}
dice_tr = lapply(1:5, 
	function(x){
		img = readnii(tr_files[[x]]["Default_OASIS"])
		th = seq(0.1, 0.6, by=0.05)
		diceTh = rep(NA, length(th))
		for(i in 1:length(th)){
  		img = img > th[i]
	  	gold = tr_golds[[x]]
		  tbl = table(c(img), c(gold))
		  diceTh[i] = dice(tbl)
		}
		return(diceTh)
	})
avgDice = Reduce('+', dice_tr)/length(dice_tr[[1]])
print(avgDice)
```

## Improving Results
- The default model is picking up a lot of false positives in the spinal cord. 
- We might improve the results by re-training the OASIS model using our five training subjects.
- To re-train using new data, binary masks of gold standard lesion segmentations are needed and should be in T1 space.


## Making OASIS data frames
- OASIS requires a particular data frame format, which we create using the function `oasis_train_dataframe`.
- Includes an option to preprocess your data (`preproc`), which does (1) inhomogeneity correction using `fsl_biascorrect`
and (2) rigid coregistration using `flirt` to the T1 space.
- Includes an option to whole-brain intensity normalize (`normalize`).
- `make_df()` below is a helper function.

```{r oasis_df_show, eval=FALSE}
make_df = function(x){
  res = oasis_train_dataframe(
      flair=tr_flairs[[x]], t1=tr_t1s[[x]], t2=tr_t2s[[x]],
      pd=tr_pds[[x]], gold_standard=tr_golds[[x]], 
      brain_mask=tr_masks[[x]], 
      preproc=FALSE, normalize=TRUE, return_preproc=FALSE)
  return(res$oasis_dataframe)
}
oasis_dfs = lapply(1:5, make_df)
```

## Training OASIS 
- The function `oasis_training` takes the data frames we made and fits a logistic regression using labels and features from a subset of voxels in each subject's brain mask (top 15\% in FLAIR intensity).
- The function `do.call` is a useful R function that applies the function named in the first argument to all elements of the list specified in the second argument. 

```{r oasis_model_show, eval=FALSE}
ms_model = do.call("oasis_training", oasis_dfs)
```

## OASIS model object

```{r oasis_model_show2}
print(ms.lesion::ms_model)
```

## Trained OASIS Model Results
```{r trained_predict_tr_run, eval=TRUE, echo=FALSE}
trained_tr = lapply(tr_files, 
  function(x){
    img = readnii(x["Trained_OASIS"])
    img = img > 0.16
    return(img)
  })
```
- Using the same threshold of 0.16.
- Dice coeffients for default vs. re-trained OASIS model

```{r table3, echo=FALSE}
tbls_tr = lapply(1:5, function(x) 
  table(c(tr_golds[[x]]), c(trained_tr[[x]])))
trDice = sapply(tbls_tr, dice)

diceTR = data.frame('Subject'=factor(1:5),
                    'Dice'=c(trDice))
diceDF$Model = "Default"
diceTR$Model = "Trained"
diceAll = rbind(diceDF, diceTR)
diceAll$Model = factor(diceAll$Model)

g = ggplot(diceAll, aes(x=Subject, y=Dice)) + 
  geom_histogram(position="dodge", stat="identity") + 
  facet_wrap(~Model)
print(g)
```


```{r dice_mat, echo = FALSE}
df = cbind(id = sprintf("%02.0f", 1:5),
           r1 = round((trDice - dfDice) / dfDice * 100, 1))
df = data.frame(df, stringsAsFactors = FALSE)
colnames(df) = c("ID", "Dice")
```
## Improvement

- Percent improvement in Dice over the default model:

```{r, echo = FALSE}
knitr::kable(df)
```



## Wrap-up
- We've covered all (or most) image pre-procssing steps in a typical image pre-processing pipeline, starting with raw nifti images. 
- Everything was done in R!

<img src="flow.png" style="width: 50%; display: block; margin: auto;"> 

## What we didn't cover
- fMRI: see `fmri` library 
- Other imaging modalities, e.g., CT, PET
	- MALF segmentation is robust
- Voxel-wise testing: see `voxel` library 
- Other population-level statistical inference: 
- Statistical/machine learning: see `caret` library


## What can you do next?
- Further modeling and statistical analysis.
- Register images to a template to do population inference.
- General R 
	- Build your own R libraries for image analysis.
	- Rmarkdown for reproducible reports
	- R shiny apps

**Resources**  

- Neurohacking tutorial on Coursera
- Neuroconductor: central repository for image analysis R libraries



## Website

[http://johnmuschelli.com/imaging_in_r](../index.html)

## References {.smaller}


